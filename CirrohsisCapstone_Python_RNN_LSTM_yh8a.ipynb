{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yhao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "C:\\Users\\yhao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:126: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\yhao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:126: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, return_sequences=True, input_shape=(89, 14))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 89, 128)           73216     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 89, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 205,187\n",
      "Trainable params: 205,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yhao\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples, validate on 16 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 1.0793 - acc: 0.4028 - val_loss: 1.1838 - val_acc: 0.3750\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.9277 - acc: 0.5903 - val_loss: 1.2258 - val_acc: 0.4375\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.8871 - acc: 0.5833 - val_loss: 1.1339 - val_acc: 0.5625\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.8375 - acc: 0.6389 - val_loss: 1.0504 - val_acc: 0.5625\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.7813 - acc: 0.6944 - val_loss: 1.0121 - val_acc: 0.5625\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.7393 - acc: 0.7014 - val_loss: 1.0205 - val_acc: 0.5625\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.7016 - acc: 0.7361 - val_loss: 1.0856 - val_acc: 0.5625\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.6330 - acc: 0.7569 - val_loss: 1.1835 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.5793 - acc: 0.7778 - val_loss: 1.3208 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.5433 - acc: 0.7639 - val_loss: 1.3963 - val_acc: 0.4375\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.4722 - acc: 0.8333 - val_loss: 1.5429 - val_acc: 0.5625\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.4131 - acc: 0.8681 - val_loss: 1.6858 - val_acc: 0.4375\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.3785 - acc: 0.8750 - val_loss: 1.7095 - val_acc: 0.4375\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.3641 - acc: 0.8681 - val_loss: 1.8159 - val_acc: 0.3750\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.2782 - acc: 0.9028 - val_loss: 1.9980 - val_acc: 0.3750\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.2886 - acc: 0.9028 - val_loss: 1.9150 - val_acc: 0.4375\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.2247 - acc: 0.9375 - val_loss: 1.9085 - val_acc: 0.4375\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.2564 - acc: 0.9167 - val_loss: 1.8883 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.2373 - acc: 0.8958 - val_loss: 1.8915 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.1842 - acc: 0.9444 - val_loss: 1.9197 - val_acc: 0.3750\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.2420 - acc: 0.9306 - val_loss: 2.0084 - val_acc: 0.3750\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.2053 - acc: 0.9028 - val_loss: 2.1537 - val_acc: 0.4375\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.1719 - acc: 0.9375 - val_loss: 2.2338 - val_acc: 0.4375\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.1090 - acc: 0.9861 - val_loss: 2.5158 - val_acc: 0.3125\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.1132 - acc: 0.9653 - val_loss: 2.7455 - val_acc: 0.3125\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.0857 - acc: 0.9792 - val_loss: 2.7612 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.0779 - acc: 0.9792 - val_loss: 2.7765 - val_acc: 0.4375\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.1904 - acc: 0.9167 - val_loss: 2.7489 - val_acc: 0.4375\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.1994 - acc: 0.9375 - val_loss: 2.5120 - val_acc: 0.4375\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.4528 - acc: 0.8611 - val_loss: 2.0482 - val_acc: 0.3750\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.3731 - acc: 0.8611 - val_loss: 2.0251 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.2991 - acc: 0.8681 - val_loss: 1.9153 - val_acc: 0.3750\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.3121 - acc: 0.8889 - val_loss: 2.1668 - val_acc: 0.2500\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.3394 - acc: 0.9097 - val_loss: 1.9680 - val_acc: 0.2500\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.2323 - acc: 0.9236 - val_loss: 1.9497 - val_acc: 0.5000\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.2530 - acc: 0.9306 - val_loss: 2.0728 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.1841 - acc: 0.9583 - val_loss: 2.4820 - val_acc: 0.3125\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.1613 - acc: 0.9444 - val_loss: 2.4820 - val_acc: 0.4375\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.1279 - acc: 0.9792 - val_loss: 2.7948 - val_acc: 0.4375\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.1690 - acc: 0.9514 - val_loss: 2.4180 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.1051 - acc: 0.9722 - val_loss: 2.3451 - val_acc: 0.4375\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.1140 - acc: 0.9514 - val_loss: 2.2649 - val_acc: 0.4375\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.1206 - acc: 0.9653 - val_loss: 2.1491 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.1032 - acc: 0.9722 - val_loss: 2.3153 - val_acc: 0.5000\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.0736 - acc: 0.9861 - val_loss: 2.4739 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.0637 - acc: 0.9792 - val_loss: 2.4926 - val_acc: 0.5000\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.0512 - acc: 0.9931 - val_loss: 2.4977 - val_acc: 0.4375\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.0463 - acc: 0.9861 - val_loss: 2.6078 - val_acc: 0.3750\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.0539 - acc: 0.9931 - val_loss: 2.7028 - val_acc: 0.4375\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.0283 - acc: 0.9931 - val_loss: 2.9931 - val_acc: 0.4375\n",
      "[[6 6 7]\n",
      " [0 8 3]\n",
      " [1 5 9]]\n",
      "[[36  3  2]\n",
      " [ 1 58  2]\n",
      " [ 0  3 55]]\n"
     ]
    }
   ],
   "source": [
    "#Reference: https://github.com/madnavs/Multivariate-Classification/blob/master/Keras.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras import optimizers\n",
    "from itertools import cycle\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(test_y, pred_y, class_names, filename):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    cmap = plt.cm.Blues\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(\n",
    "        np.argmax(test_y, axis=1), np.argmax(pred_y, axis=1))\n",
    "    np.set_printoptions(precision=2)\n",
    "    # Plot confusion matrix\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(\"LSTM Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(filename + \".png\")\n",
    "    # Plot normalized confusion matrix\n",
    "\n",
    "\n",
    "def plotroc(test_y, pred_y, n_classes, filename):\n",
    "    \"\"\"\n",
    "    Compute ROC curve and ROC area for each class\n",
    "    \"\"\"\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    threshold = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], threshold[i] = roc_curve(test_y[:, i], pred_y[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    lw = 1\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'''.\n",
    "                 format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1])\n",
    "    plt.ylim([0.0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('LSTM Performance')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(filename + '.png')\n",
    "    return\n",
    "\n",
    "\n",
    "#def read_data(file_path):\n",
    "#    data = pd.read_csv(file_path, header=0)\n",
    "#    return data\n",
    "\n",
    "\n",
    "#def windows(data, window_size):\n",
    "#    start = 0\n",
    "#    while start < len(data):\n",
    "#        yield start, start + window_size - 1\n",
    "#        start += (window_size)\n",
    "\n",
    "\n",
    "#def extract_segments(data, window_size):\n",
    "#    segments = None\n",
    "#    labels = np.empty((0))\n",
    "#    for (start, end) in windows(data, window_size):\n",
    "#        if (len(data.ix[start:end]) == (window_size)):\n",
    "#            signal = np.asarray(data.ix[start:end])[:,2:16]\n",
    "#            if segments is None:\n",
    "#                segments = signal\n",
    "#            else:\n",
    "#                segments = np.vstack([segments, signal])\n",
    "#            labels = np.append(labels, data.ix[start:end][\"MorIndex\"][start])\n",
    "#    return segments, labels\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \"\"\"Hyperparameters\"\"\"\n",
    "    win_size = 3   # rows for each patient\n",
    "    num_var = 30   # number of features\n",
    "    #split_ratio = 0.8\n",
    "\n",
    "    \"\"\"Load data:\n",
    "    segment: Each time series of 89 samples (rows each patient) is named as segment.\n",
    "    label: Each segment is associated with a label\n",
    "    \"\"\"\n",
    "    #data = read_data(\"Multi-variate-Time-series-Data.xlsx\")\n",
    "    #segments, labels = extract_segments(data, win_size)\n",
    "    #labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)\n",
    "    #reshaped_segments = segments.reshape(\n",
    "    #     [int(len(segments) / (win_size)), (win_size), num_var])\n",
    "\n",
    "    \"\"\"Create Train and Test Split based on split ratio\"\"\"\n",
    "\n",
    "   # train_test_split = np.random.rand(len(reshaped_segments)) < split_ratio\n",
    "   # train_x = reshaped_segments[train_test_split]\n",
    "   # train_y = labels[train_test_split]\n",
    "   # test_x = reshaped_segments[~train_test_split]\n",
    "   # test_y = labels[~train_test_split]\n",
    "\n",
    "    \n",
    "    # Create and fit the LSTM network\n",
    "    # Parameter setting split_ratio = 0.8 learning rate=0.001 nb_epoch=50 batch_size=64\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_dim=num_var, input_length=win_size, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                          epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # Fit the network\n",
    "       \n",
    "    model.fit(train_x, train_y, nb_epoch=50, batch_size=64,\n",
    "              verbose=2, validation_split=0.1)\n",
    "\n",
    "    # Predict Test Data and Plot ROC\n",
    "    pred_y = model.predict(test_x, batch_size=64, verbose=2)\n",
    "    plotroc(test_y, pred_y, 2, 'test_roc')\n",
    "    class_names = ['Class 0', 'Class 1']\n",
    "    plot_confusion_matrix(test_y, pred_y, class_names, 'test_conf')\n",
    "\n",
    "    pred_y = model.predict(train_x, batch_size=64, verbose=2)\n",
    "    plotroc(train_y, pred_y, 2, 'train_roc1')\n",
    "    plot_confusion_matrix(train_y, pred_y, class_names, 'train_conf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
